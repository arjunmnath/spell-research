{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"Transformer_Combined.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"64fb7c3624f54fbabc704ab6969be147":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c612cbd1924b4413bfd78447d870dbab","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5a650871a286475693488236de641a70","IPY_MODEL_9a965bfc3f63449893d8db24f1f085a0"]}},"c612cbd1924b4413bfd78447d870dbab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5a650871a286475693488236de641a70":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6958c2bbc0c240989b7b181ffd58d971","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":512,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":512,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_12aa02b51488408586344ad8495b2356"}},"9a965bfc3f63449893d8db24f1f085a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_77feb7fb6d2b491fbe475a61ea304999","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 512/512 [00:00&lt;00:00, 929B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0628a7c41f4b4375b1517ca4540eb7be"}},"6958c2bbc0c240989b7b181ffd58d971":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"12aa02b51488408586344ad8495b2356":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"77feb7fb6d2b491fbe475a61ea304999":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0628a7c41f4b4375b1517ca4540eb7be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3254ab336208493f84a428c40dceceb1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6dc31f44cb4542fb8a5ff69f631f0b7f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_930f266e093c478094a948801b39ede3","IPY_MODEL_0a0be45164e94f61b6d15f060bdec062"]}},"6dc31f44cb4542fb8a5ff69f631f0b7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"930f266e093c478094a948801b39ede3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6eba6089c09142cfabd132026f4b92f7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":5069051,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5069051,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_28d6c441219a4f8fa311346f2119ec54"}},"0a0be45164e94f61b6d15f060bdec062":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e580b3927c3b402e823245f036960e94","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5.07M/5.07M [00:01&lt;00:00, 4.11MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa57eabc87b64d3db3fe3ffcc9aea236"}},"6eba6089c09142cfabd132026f4b92f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"28d6c441219a4f8fa311346f2119ec54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e580b3927c3b402e823245f036960e94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aa57eabc87b64d3db3fe3ffcc9aea236":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b827f9623cc043bf9921b4ea2372ea27":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5b21dd33a9fd4bc982bc5d8c440f598a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3bd66fe23e7847d68113f29758eb7a3a","IPY_MODEL_9b58bdd6c9c84905b48bd7179d8bd350"]}},"5b21dd33a9fd4bc982bc5d8c440f598a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3bd66fe23e7847d68113f29758eb7a3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d0b48b40e2ae4e1fa29620a3c454000a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1115590446,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1115590446,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ac020713bab242e68d4914bbdb0bee6b"}},"9b58bdd6c9c84905b48bd7179d8bd350":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ef6f3c35f05947c1b80795a674c49cdd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.12G/1.12G [00:27&lt;00:00, 39.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b23d311931014921a58a1dc7522c8e06"}},"d0b48b40e2ae4e1fa29620a3c454000a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ac020713bab242e68d4914bbdb0bee6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef6f3c35f05947c1b80795a674c49cdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b23d311931014921a58a1dc7522c8e06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/arjunmnath/indic-trans.git\n%cd indic-trans/\n!pip install -r requirements.txt\n!python setup.py install\n\n\nimport sys\nimport os\nfrom IPython.display import clear_output\n\ndst = [path for path in sys.path if 'site-packages' in path or 'dist-packages' in path][0]\nsrc = [path for path in os.listdir('build') if 'lib' in path][0]\nimport shutil\nshutil.move(f\"./build/{src}\", dst)\n%cd ..\nclear_output(wait=True)\nprint()\nfrom indictrans import Transliterator\ntrn = Transliterator(source='mal', target='eng', build_lookup=True)\ntrn.transform(\"നാട്ടിൽ എവിടാ?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:02:51.092025Z","iopub.execute_input":"2025-08-09T04:02:51.092396Z","iopub.status.idle":"2025-08-09T04:03:36.948804Z","shell.execute_reply.started":"2025-08-09T04:02:51.092364Z","shell.execute_reply":"2025-08-09T04:03:36.947815Z"}},"outputs":[{"name":"stdout","text":"\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'natiൽ evita?'"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"!pip install sentencepiece==0.1.94\n!pip install demoji\n!pip install tweet-preprocessor\n# !pip install transformers[sentencepiece]","metadata":{"id":"0n47rpqSqWne","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610288059409,"user_tz":-330,"elapsed":198428,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"outputId":"ded44783-4a1a-4479-f1e9-6a7e25162276","trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:03:36.950505Z","iopub.execute_input":"2025-08-09T04:03:36.951016Z","iopub.status.idle":"2025-08-09T04:04:40.374008Z","shell.execute_reply.started":"2025-08-09T04:03:36.950984Z","shell.execute_reply":"2025-08-09T04:04:40.373128Z"}},"outputs":[{"name":"stdout","text":"Collecting sentencepiece==0.1.94\n  Downloading sentencepiece-0.1.94.tar.gz (507 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.5/507.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: sentencepiece\n  Building wheel for sentencepiece (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for sentencepiece: filename=sentencepiece-0.1.94-cp311-cp311-linux_x86_64.whl size=1429147 sha256=2ebe410d98a232ccd963f17e4d6f36116439116ce729a68ee7d3d7afb68726c4\n  Stored in directory: /root/.cache/pip/wheels/77/53/cc/16f215296aca9a7bd71a835fc01b332dbeebfd019d1b478216\nSuccessfully built sentencepiece\nInstalling collected packages: sentencepiece\n  Attempting uninstall: sentencepiece\n    Found existing installation: sentencepiece 0.2.0\n    Uninstalling sentencepiece-0.2.0:\n      Successfully uninstalled sentencepiece-0.2.0\nSuccessfully installed sentencepiece-0.1.94\nCollecting demoji\n  Downloading demoji-1.1.0-py3-none-any.whl.metadata (9.2 kB)\nDownloading demoji-1.1.0-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: demoji\nSuccessfully installed demoji-1.1.0\nCollecting tweet-preprocessor\n  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl.metadata (5.9 kB)\nDownloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\nInstalling collected packages: tweet-preprocessor\nSuccessfully installed tweet-preprocessor-0.6.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import gdown\nfolder_ids = [\"1GGVncH-e6J_dfi6IVixC7LpM7mBjJZLJ\", '1UccJUHZqvLD39kkoAB5BIaOtBNwYf4vZ']\nfor id in folder_ids:\n    gdown.download_folder(id=id)\nclear_output(wait=True); print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:04:40.375189Z","iopub.execute_input":"2025-08-09T04:04:40.375460Z","iopub.status.idle":"2025-08-09T04:05:34.027993Z","shell.execute_reply.started":"2025-08-09T04:04:40.375436Z","shell.execute_reply":"2025-08-09T04:05:34.027348Z"}},"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom transformers import AutoModel, AutoTokenizer\nimport torch.nn as nn\nimport torch\nimport copy\nfrom transformers import BertModel, RobertaModel, BertTokenizer, RobertaTokenizer, get_linear_schedule_with_warmup\nfrom torch.utils.data import TensorDataset, RandomSampler, SequentialSampler, random_split, DataLoader, IterableDataset, ConcatDataset\nimport sklearn\nfrom torch.optim import AdamW\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import f1_score \nfrom tqdm import tqdm\nimport demoji \nimport random\ndemoji.download_codes() \nimport preprocessor as p\nfrom indictrans import Transliterator\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.RESERVED)\nplt.rcParams['figure.figsize'] = [15, 8]\nplt.rcParams.update({'font.size': 8})\nRANDOM_SEED = 42\nmodel_path = 'ai4bharat/indic-bert'\nmodel_path = 'xlm-roberta-base'\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"9vOLxNuZlk4m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610288144191,"user_tz":-330,"elapsed":6965,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"outputId":"18361cca-570f-4a31-d498-dcd6e9c6454d","trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:05:34.028788Z","iopub.execute_input":"2025-08-09T04:05:34.029168Z","iopub.status.idle":"2025-08-09T04:06:15.010547Z","shell.execute_reply.started":"2025-08-09T04:05:34.029149Z","shell.execute_reply":"2025-08-09T04:06:15.009761Z"}},"outputs":[{"name":"stderr","text":"2025-08-09 04:05:59.965057: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754712360.334117      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754712360.440281      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/tmp/ipykernel_36/3773339689.py:18: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n  demoji.download_codes()\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def random_seed(seed_value, use_cuda):\n    np.random.seed(seed_value)  \n    torch.manual_seed(seed_value)  \n    random.seed(seed_value)\n    if use_cuda:\n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)  \n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\nrandom_seed(RANDOM_SEED, True)","metadata":{"id":"72QHLh_2T-dA","executionInfo":{"status":"ok","timestamp":1610288144193,"user_tz":-330,"elapsed":6795,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:06:15.012720Z","iopub.execute_input":"2025-08-09T04:06:15.013580Z","iopub.status.idle":"2025-08-09T04:06:15.026768Z","shell.execute_reply.started":"2025-08-09T04:06:15.013554Z","shell.execute_reply":"2025-08-09T04:06:15.026070Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class Dataset_OLID():\n    def __init__(self, train_data, batch_size = 32):\n        self.train_data = train_data\n        self.batch_size = batch_size\n\n        self.label_dict = {'Not_offensive': 0,\n                            'Offensive_Targeted_Insult_Group': 3,\n                            'Offensive_Targeted_Insult_Individual': 2,\n                            'Offensive_Targeted_Insult_Other': 4,\n                            'Offensive_Untargetede': 1}\n                                    \n        self.count_dic = {}\n        self.train_dataset = self.process_data(self.train_data)\n\n    def tokenize(self, sentences, padding = True, max_len = 256):\n        tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n        input_ids, attention_masks = [], []\n        for sent in sentences:\n            encoded_dict = tokenizer.encode_plus(sent,\n                                                    add_special_tokens=True,\n                                                    max_length=max_len, \n                                                    padding='max_length', \n                                                    return_attention_mask = True,\n                                                    return_tensors = 'pt', \n                                                    truncation = True)\n            input_ids.append(encoded_dict['input_ids'])\n            attention_masks.append(encoded_dict['attention_mask'])\n        \n        input_ids = torch.cat(input_ids, dim=0)\n        attention_masks = torch.cat(attention_masks, dim=0)\n\n        return {'input_ids': (input_ids), 'attention_masks': (attention_masks)}\n    \n    def process_data(self, data):\n        sentences, labels = [], []\n        print(len(data))\n        for id,line in enumerate(data):\n            if id==0: continue\n            sentence = line.strip().split('\\t')\n            label = sentence[2:]\n\n            if label[0] == 'NOT': labels.append(0)\n            elif label[1] == 'UNT': labels.append(1)\n            elif label[2] == 'IND': labels.append(2)\n            elif label[2] == 'GRP': labels.append(3)\n            else: labels.append(4)\n\n            sentence = sentence[1].replace('#','').lower()\n            emoji_dict = demoji.findall(sentence)\n            if len(emoji_dict): \n                for emoji, text in emoji_dict.items():\n                    sentence = sentence.replace(emoji, ' '+text+' ')\n                    sentence = ' '.join(sentence.split())\n            sentences.append(sentence)\n            self.count_dic[labels[-1]] = self.count_dic.get(labels[-1], 0) + 1\n        inputs = self.tokenize(sentences)\n        return TensorDataset(inputs['input_ids'], inputs['attention_masks'], torch.Tensor(labels))\n    \n    def get_dataloader(self, inputs, labels, train = True):\n        data = TensorDataset(inputs['input_ids'], inputs['attention_masks'], labels)\n        if train:\n            sampler = RandomSampler(data)\n        else:\n            sampler = SequentialSampler(data)\n        return DataLoader(data, sampler=sampler, batch_size=self.batch_size)","metadata":{"id":"aC01VIjXBDaX","executionInfo":{"status":"ok","timestamp":1610288144194,"user_tz":-330,"elapsed":5020,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:06:15.027534Z","iopub.execute_input":"2025-08-09T04:06:15.027796Z","iopub.status.idle":"2025-08-09T04:06:15.054351Z","shell.execute_reply.started":"2025-08-09T04:06:15.027770Z","shell.execute_reply":"2025-08-09T04:06:15.053422Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"with open('olid/olid-training-v1.0.tsv', 'r') as f:\n    train_data = f.readlines()\nolid_data = Dataset_OLID(train_data)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":135,"referenced_widgets":["64fb7c3624f54fbabc704ab6969be147","c612cbd1924b4413bfd78447d870dbab","5a650871a286475693488236de641a70","9a965bfc3f63449893d8db24f1f085a0","6958c2bbc0c240989b7b181ffd58d971","12aa02b51488408586344ad8495b2356","77feb7fb6d2b491fbe475a61ea304999","0628a7c41f4b4375b1517ca4540eb7be","3254ab336208493f84a428c40dceceb1","6dc31f44cb4542fb8a5ff69f631f0b7f","930f266e093c478094a948801b39ede3","0a0be45164e94f61b6d15f060bdec062","6eba6089c09142cfabd132026f4b92f7","28d6c441219a4f8fa311346f2119ec54","e580b3927c3b402e823245f036960e94","aa57eabc87b64d3db3fe3ffcc9aea236"]},"id":"peoybAjPBGhU","executionInfo":{"status":"ok","timestamp":1610288159144,"user_tz":-330,"elapsed":19274,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"outputId":"5f509ac8-c511-43ef-82a5-672d576b8561","trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:06:15.055170Z","iopub.execute_input":"2025-08-09T04:06:15.055462Z","iopub.status.idle":"2025-08-09T04:06:35.035860Z","shell.execute_reply.started":"2025-08-09T04:06:15.055435Z","shell.execute_reply":"2025-08-09T04:06:35.035173Z"}},"outputs":[{"name":"stdout","text":"13241\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c36bef58ab8447685c959d0eede0e6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c7826b1e083461d948d0500e0b19dd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da01199106184b43b809b47f0c030b31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"495a1dfb88f848288209a9213ca3104e"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"tr1 = Transliterator(source='tam', target='eng', build_lookup=True)\ntr2 = Transliterator(source='mal', target='eng', build_lookup=True)\ntr3 = Transliterator(source='kan', target='eng', build_lookup=True)","metadata":{"id":"LpfSw70pkm4z","executionInfo":{"status":"ok","timestamp":1610288159553,"user_tz":-330,"elapsed":19194,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:06:35.036658Z","iopub.execute_input":"2025-08-09T04:06:35.036947Z","iopub.status.idle":"2025-08-09T04:06:35.520858Z","shell.execute_reply.started":"2025-08-09T04:06:35.036921Z","shell.execute_reply":"2025-08-09T04:06:35.520269Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class Dataset():\n    def __init__(self, train_data, val_data, batch_size = 32):\n        self.train_data = train_data\n        self.val_data = val_data\n        self.batch_size = batch_size\n\n        self.label_dict = {'Not_offensive': 0,\n                            'Offensive_Targeted_Insult_Group': 3,\n                            'Offensive_Targeted_Insult_Individual': 2,\n                            'Offensive_Targeted_Insult_Other': 4,\n                            'Offensive_Untargetede': 1}\n        self.count_dic = {}\n        self.train_dataset = self.process_data(self.train_data)\n        self.val_dataset = self.process_data(self.val_data)\n\n        \n        # self.train_dataloader = self.get_dataloader(self.train_inputs, self.train_labels)\n        # self.val_dataloader = self.get_dataloader(self.val_inputs, self. val_labels, train = False)\n\n    def tokenize(self, sentences, padding = True, max_len = 256):\n        tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n        input_ids, attention_masks = [], []\n        for sent in sentences:\n            encoded_dict = tokenizer.encode_plus(sent,\n                                                    add_special_tokens=True,\n                                                    max_length=max_len, \n                                                    padding='max_length', \n                                                    return_attention_mask = True,\n                                                    return_tensors = 'pt', \n                                                    truncation = True)\n            input_ids.append(encoded_dict['input_ids'])\n            attention_masks.append(encoded_dict['attention_mask'])\n        input_ids = torch.cat(input_ids, dim=0)\n        attention_masks = torch.cat(attention_masks, dim=0)\n        return {'input_ids': input_ids, 'attention_masks': attention_masks}\n    \n    def process_data(self, data):\n        tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n        sentences, labels = [], []\n        for line in data:\n            sentence = line.strip().split('\\t')\n            label = sentence.pop()\n            if label not in self.label_dict: continue\n            # print('label found')\n            sentence = ((' '+tokenizer.sep_token+' ').join(sentence)).replace('#','').lower()\n            sentence = tr3.transform(tr2.transform(tr1.transform(sentence)))\n            # sentence = p.clean(' '.join(sentence)).replace('#','')\n            emoji_dict = demoji.findall(sentence)\n            if len(emoji_dict): \n                for emoji, text in emoji_dict.items():\n                    sentence = sentence.replace(emoji, ' '+text+' ')\n                    sentence = ' '.join(sentence.split())\n            sentences.append(sentence)\n            # if label =='Not_offensive': labels.append(0)\n            # else:\n            labels.append(self.label_dict[label])\n            self.count_dic[labels[-1]] = self.count_dic.get(labels[-1], 0) + 1\n        inputs = self.tokenize(sentences)\n\n        return TensorDataset(inputs['input_ids'], inputs['attention_masks'], torch.Tensor(labels))\n    \n    def get_dataloader(self, inputs, labels, train = True):\n        data = TensorDataset(inputs['input_ids'], inputs['attention_masks'], labels)\n        if train:\n            sampler = RandomSampler(data)\n        else:\n            sampler = SequentialSampler(data)\n        return DataLoader(data, sampler=sampler, batch_size=self.batch_size)","metadata":{"id":"VIOPL_OTrRy4","executionInfo":{"status":"ok","timestamp":1610288159553,"user_tz":-330,"elapsed":18744,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:06:35.521622Z","iopub.execute_input":"2025-08-09T04:06:35.521890Z","iopub.status.idle":"2025-08-09T04:06:35.531952Z","shell.execute_reply.started":"2025-08-09T04:06:35.521866Z","shell.execute_reply":"2025-08-09T04:06:35.531366Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"with open('/kaggle/working/FIRE-2025/Kannada/kannada_offensive_train.csv', 'r') as f:\n    train_data = f.readlines()\nwith open('/kaggle/working/FIRE-2025/Kannada/kannada_offensive_dev.csv', 'r') as f:\n    val_data = f.readlines()\nkan_data = Dataset(train_data, val_data)\n\nwith open('/kaggle/working/FIRE-2025/Malayalam/mal_full_offensive_train.csv', 'r') as f:\n    train_data = f.readlines()\nwith open('/kaggle/working/FIRE-2025/Malayalam/mal_full_offensive_dev.csv', 'r') as f:\n    val_data = f.readlines()\nmal_data = Dataset(train_data, val_data)\n\nwith open('/kaggle/working/FIRE-2025/Tamil/tamil_offensive_full_train.csv', 'r') as f:\n    train_data = f.readlines()\nwith open('/kaggle/working/FIRE-2025/Tamil/tamil_offensive_full_dev.csv', 'r') as f:\n    val_data = f.readlines()\ntam_data = Dataset(train_data, val_data)","metadata":{"id":"0HBnekZFnnhe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610288289303,"user_tz":-330,"elapsed":148054,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"outputId":"0f9eb471-8db3-4d0e-f96c-f18fd6e376a1","trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:06:35.532678Z","iopub.execute_input":"2025-08-09T04:06:35.532878Z","iopub.status.idle":"2025-08-09T04:08:51.627778Z","shell.execute_reply.started":"2025-08-09T04:06:35.532862Z","shell.execute_reply":"2025-08-09T04:08:51.626777Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Save and Load Functions\ndef save_metrics(save_path, epochs, model, optimizer, F1):\n\n    state_dict = {'model_state_dict': model.state_dict(),\n                  'optimizer_state_dict': optimizer.state_dict(),\n                  'epochs': epochs+1,\n                  'F1': F1}\n    \n    torch.save(state_dict, save_path)\n    print(f'Model saved to ==> {save_path}')\n\n\ndef load_metrics(load_path, model, optimizer):\n    try: \n        state_dict = torch.load(load_path, map_location=device)\n        model.load_state_dict(state_dict['model_state_dict'])\n        optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n    except: \n        state_dict = {}\n\n    print(f'Model loaded from <== {load_path}')\n    \n    return state_dict.get('epochs', 0), state_dict.get('F1', 0)","metadata":{"id":"igSNYLB6D1G8","executionInfo":{"status":"ok","timestamp":1610288425483,"user_tz":-330,"elapsed":1011,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:08:51.629056Z","iopub.execute_input":"2025-08-09T04:08:51.629352Z","iopub.status.idle":"2025-08-09T04:08:51.636349Z","shell.execute_reply.started":"2025-08-09T04:08:51.629322Z","shell.execute_reply":"2025-08-09T04:08:51.635284Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class Embedding(torch.nn.Module):\n    def __init__(self):\n        super(Embedding, self).__init__()\n        self.embeddings = AutoModel.from_pretrained(model_path)\n        self.dropout = nn.Dropout(0.3)\n        self.output_vector_size = self.embeddings.config.hidden_size * 2\n\n    def forward(self, input_ids, mask):\n        outputs = self.embeddings(input_ids, mask)\n        out = outputs.last_hidden_state # -> (batch_size, num_words, 768)\n        mean_pooling = torch.mean(out, 1)\n        max_pooling, _ = torch.max(out, 1)\n        embed = torch.cat((mean_pooling, max_pooling), 1) # -> (batch_size, 768 * 2)\n        y_pred = self.dropout(embed)\n        return y_pred\n\n\nclass HANFE(nn.Module):\n    def __init__(self, input_vector_size, hidden_size=128, dropout_prob=0.3, num_heads=4):\n        super(HANFE, self).__init__()\n        self.word_rnn = nn.LSTM(input_vector_size, hidden_size, batch_first=True)\n        self.word_attention = nn.MultiheadAttention(embed_dim=hidden_size, num_heads=num_heads, batch_first=True)\n\n        self.sentence_rnn = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n        self.sentence_attention = nn.MultiheadAttention(embed_dim=hidden_size, num_heads=num_heads, batch_first=True)\n\n    def forward(self, x):\n        x = x.unsqueeze(1)\n        word_out, _ = self.word_rnn(x)\n        word_out = word_out.permute(1, 0, 2)\n        word_attended, _ = self.word_attention(word_out, word_out, word_out)  \n        word_attended = word_attended.permute(1, 0, 2)  \n        word_attended = word_attended.mean(dim=1)  \n        \n        sentence_out, _ = self.sentence_rnn(word_attended.unsqueeze(1)) \n        sentence_out = sentence_out.permute(1, 0, 2) \n        sentence_attended, _ = self.sentence_attention(sentence_out, sentence_out, sentence_out)  \n        sentence_attended = sentence_attended.permute(1, 0, 2)  \n        sentence_attended = sentence_attended.mean(dim=1)  \n\n        return sentence_attended\n\nclass Classifier(nn.Module):\n    def __init__(self, hidden_size=128, num_classes=5, dropout_prob=0.3):\n        super(Classifier, self).__init__()\n        self.dropout = nn.Dropout(dropout_prob)\n        self.fc1 = nn.Linear(hidden_size, hidden_size, bias=True)\n        self.fc2 = nn.Linear(hidden_size, num_classes, bias=True)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.fc2(x)\n        return x\n        # x = self.dropout(x)\n        # x = self.relu(x)\n        # logits = self.fc2(x)\n        # return logits\n\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.embed = Embedding()\n        self.fe = HANFE(self.embed.output_vector_size)\n        self.classifier = Classifier()\n\n    def forward(self, input_ids, mask):\n        x = self.embed(input_ids, mask)\n        x = self.fe(x)\n        logits = self.classifier(x)\n        return logits\n","metadata":{"id":"zJTMSkNXrcjI","executionInfo":{"status":"ok","timestamp":1610288426081,"user_tz":-330,"elapsed":1461,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:08:51.637153Z","iopub.execute_input":"2025-08-09T04:08:51.638026Z","iopub.status.idle":"2025-08-09T04:08:51.660483Z","shell.execute_reply.started":"2025-08-09T04:08:51.638008Z","shell.execute_reply":"2025-08-09T04:08:51.659650Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n \ndef get_predicted(preds):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    return pred_flat\n \ndef evaluate(test_dataloader, model):\n    model.eval()\n    y_preds, y_test = np.array([]), np.array([])\n\n    for batch in test_dataloader:\n        b_input_ids, b_input_mask, b_labels = batch[0].to(device), batch[1].to(device), batch[2].to(device).long()\n        with torch.no_grad():        \n            ypred = model(b_input_ids, b_input_mask)\n        ypred = ypred.cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        y_preds = np.hstack((y_preds, get_predicted(ypred)))\n        y_test = np.hstack((y_test, label_ids))\n\n    weighted_f1 = f1_score(y_test, y_preds, average='weighted')\n    return weighted_f1, y_preds, y_test\n \ndef train(training_dataloader, validation_dataloader, model, filepath, weights = None, learning_rate = 2e-5, epochs = 4, print_every = 10):\n    total_steps = len(training_dataloader) * epochs\n    torch.cuda.empty_cache()\n    no_decay = ['bias', 'LayerNorm.weight', 'LayerNorm.bias']\n    optimizer_grouped_parameters = [\n        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n    ]\n    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps = 1e-8)\n    scheduler = get_linear_schedule_with_warmup(optimizer, \n                                                num_warmup_steps = 0, # Default value in run_glue.py\n                                                num_training_steps = total_steps)\n    \n    current_epoch, best_weighted_f1 = load_metrics(filepath, model, optimizer)\n    if weights == None:\n        criterion = nn.CrossEntropyLoss()\n    else:\n        criterion = nn.CrossEntropyLoss(weight=weights)\n    for epoch_i in range(current_epoch, epochs):\n        model.train()\n        for batch in tqdm(training_dataloader):\n            b_input_ids, b_input_mask, b_labels = batch[0].to(device), batch[1].to(device), batch[2].to(device).long()\n            \n            outputs = model(b_input_ids, b_input_mask)\n            loss = criterion(outputs, b_labels)\n \n            # if step%print_every == 0:\n            #     print(loss.item())\n \n            optimizer.zero_grad()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n \n        print('### Validation Set Stats')\n        weighted_f1, ypred, ytest = evaluate(validation_dataloader, model)\n        print(f\"  Weighted F1 {epoch_i}: {weighted_f1:.4f}\")\n        if weighted_f1 > best_weighted_f1:\n            best_weighted_f1 = weighted_f1\n            save_metrics(filepath, epoch_i, model.module.embed.embeddings, optimizer, weighted_f1)","metadata":{"id":"NFqtqQcPvli0","executionInfo":{"status":"ok","timestamp":1610288427925,"user_tz":-330,"elapsed":1673,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:08:51.661628Z","iopub.execute_input":"2025-08-09T04:08:51.661890Z","iopub.status.idle":"2025-08-09T04:08:51.691859Z","shell.execute_reply.started":"2025-08-09T04:08:51.661869Z","shell.execute_reply":"2025-08-09T04:08:51.691159Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# train_dataset = ConcatDataset([olid_data.train_dataset, kan_data.train_dataset, mal_data.train_dataset, tam_data.train_dataset])\n# train_dataset = ConcatDataset([mal_data.train_dataset, tam_data.train_dataset])\ntrain_dataset = ConcatDataset([mal_data.train_dataset, olid_data.train_dataset])\nval_dataset = mal_data.val_dataset","metadata":{"id":"8I0rCdWUsV2t","executionInfo":{"status":"ok","timestamp":1610288429104,"user_tz":-330,"elapsed":706,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:08:51.694486Z","iopub.execute_input":"2025-08-09T04:08:51.694687Z","iopub.status.idle":"2025-08-09T04:08:51.715731Z","shell.execute_reply.started":"2025-08-09T04:08:51.694672Z","shell.execute_reply":"2025-08-09T04:08:51.715017Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"count_dic = {}\nfor data in train_dataset:\n    label = int(data[2])\n    count_dic[label] = count_dic.get(label, 0)+1\nweights = torch.Tensor([1+np.log(len(train_dataset)/count_dic[i]) for i in range(5)]).to(device)","metadata":{"id":"zCexT0UutcJv","executionInfo":{"status":"ok","timestamp":1610288444638,"user_tz":-330,"elapsed":16125,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:08:51.716658Z","iopub.execute_input":"2025-08-09T04:08:51.716919Z","iopub.status.idle":"2025-08-09T04:08:52.165867Z","shell.execute_reply.started":"2025-08-09T04:08:51.716897Z","shell.execute_reply":"2025-08-09T04:08:52.165129Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"weights","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OYMEeB0grZtX","executionInfo":{"status":"ok","timestamp":1610288444640,"user_tz":-330,"elapsed":14137,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"outputId":"fa266a0b-3345-45e9-a5f2-4185a2e5e59a","trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:08:52.166700Z","iopub.execute_input":"2025-08-09T04:08:52.166980Z","iopub.status.idle":"2025-08-09T04:08:52.643463Z","shell.execute_reply.started":"2025-08-09T04:08:52.166956Z","shell.execute_reply":"2025-08-09T04:08:52.642720Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor([1.1957, 4.6664, 3.3578, 4.1370, 5.2598], device='cuda:0')"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"len(train_dataset)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44rgiKy5oCks","executionInfo":{"status":"ok","timestamp":1610288444640,"user_tz":-330,"elapsed":13081,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"outputId":"69a80666-3943-4739-a087-990dcaa7555b","trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:08:52.644301Z","iopub.execute_input":"2025-08-09T04:08:52.644582Z","iopub.status.idle":"2025-08-09T04:08:52.650287Z","shell.execute_reply.started":"2025-08-09T04:08:52.644559Z","shell.execute_reply":"2025-08-09T04:08:52.649434Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"27963"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"print(len(mal_data.train_dataset), len(olid_data.train_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:08:52.651106Z","iopub.execute_input":"2025-08-09T04:08:52.651427Z","iopub.status.idle":"2025-08-09T04:08:52.665678Z","shell.execute_reply.started":"2025-08-09T04:08:52.651410Z","shell.execute_reply":"2025-08-09T04:08:52.664985Z"}},"outputs":[{"name":"stdout","text":"14723 13240\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=64)\nval_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=128)","metadata":{"id":"cjCQc8metC-U","executionInfo":{"status":"ok","timestamp":1610288446664,"user_tz":-330,"elapsed":1263,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:08:52.666383Z","iopub.execute_input":"2025-08-09T04:08:52.666919Z","iopub.status.idle":"2025-08-09T04:08:52.681558Z","shell.execute_reply.started":"2025-08-09T04:08:52.666898Z","shell.execute_reply":"2025-08-09T04:08:52.680843Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"model = Model().to(device)\nmodel = nn.DataParallel(model)\nmodel = torch.compile(model)\noptimizer = AdamW(model.parameters(), lr=3e-5, eps = 1e-8)\n# load_metrics('olid_kannada_mbert.pt', model, optimizer)","metadata":{"id":"YMgZPosD1sTc","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["b827f9623cc043bf9921b4ea2372ea27","5b21dd33a9fd4bc982bc5d8c440f598a","3bd66fe23e7847d68113f29758eb7a3a","9b58bdd6c9c84905b48bd7179d8bd350","d0b48b40e2ae4e1fa29620a3c454000a","ac020713bab242e68d4914bbdb0bee6b","ef6f3c35f05947c1b80795a674c49cdd","b23d311931014921a58a1dc7522c8e06"]},"executionInfo":{"status":"ok","timestamp":1610288480364,"user_tz":-330,"elapsed":34049,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"outputId":"eb6cd633-7cb5-4866-d6bc-f1eefc94068c","trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:08:52.682379Z","iopub.execute_input":"2025-08-09T04:08:52.682572Z","iopub.status.idle":"2025-08-09T04:09:04.591910Z","shell.execute_reply.started":"2025-08-09T04:08:52.682559Z","shell.execute_reply":"2025-08-09T04:09:04.591114Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19c7b2737ba84385b9a32fb1ec472f73"}},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:09:04.592864Z","iopub.execute_input":"2025-08-09T04:09:04.593148Z","iopub.status.idle":"2025-08-09T04:09:04.597142Z","shell.execute_reply.started":"2025-08-09T04:09:04.593127Z","shell.execute_reply":"2025-08-09T04:09:04.596358Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"train(train_dataloader, val_dataloader, model, 'olid_xlmr_base_embed_new.pt', weights=weights, epochs=4)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k0ufvYfIYwuS","executionInfo":{"status":"ok","timestamp":1610302974269,"user_tz":-330,"elapsed":8609958,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"18426363469360203926"}},"outputId":"fa50db00-49c0-412e-c626-c9905d32d631","trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:09:04.598484Z","iopub.execute_input":"2025-08-09T04:09:04.598676Z"}},"outputs":[{"name":"stdout","text":"Model loaded from <== olid_xlmr_base_embed_new.pt\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/437 [00:00<?, ?it/s]W0809 04:09:04.686000 36 torch/_logging/_internal.py:1089] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/variables/functions.py:679: UserWarning: Graph break due to unsupported builtin sys._getframe. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.\n  torch._dynamo.utils.warn_once(msg)\n100%|██████████| 437/437 [12:42<00:00,  1.74s/it]\n","output_type":"stream"},{"name":"stdout","text":"### Validation Set Stats\n  Weighted F1 0: 0.9537\nModel saved to ==> olid_xlmr_base_embed_new.pt\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 437/437 [12:42<00:00,  1.75s/it]\n","output_type":"stream"},{"name":"stdout","text":"### Validation Set Stats\n  Weighted F1 1: 0.9537\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 437/437 [12:41<00:00,  1.74s/it]\n","output_type":"stream"},{"name":"stdout","text":"### Validation Set Stats\n  Weighted F1 2: 0.9537\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 237/437 [06:53<05:49,  1.75s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"_, ypred, ytest = evaluate(val_dataloader , model)\nfrom sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, precision_recall_fscore_support, roc_auc_score, classification_report\narray = confusion_matrix(ytest, ypred)","metadata":{"id":"quTk_hanRRav","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ytest.shape, ypred.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"precision, recall, f1, _ = precision_recall_fscore_support(\n                ytest, ypred, average='weighted', zero_division=0\n            )\naccuracy = accuracy_score(ytest, ypred)\nfpr, tpr, thresholds = roc_curve(ytest, ypred)\nroc_auc = auc(fpr, tpr)\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"precision: {precision: .4f}\")\nprint(f\"recall: {recall: .4f}\")\nprint(f\"f1: {f1: .4f}\")\nprint(f\"AUC: {roc_auc:.4f}\")\nprint(classification_report(ytest, ypred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sn\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf_cm = pd.DataFrame(array, range(5), range(5))\n# plt.figure(figsize=(10,7))\nsn.set(font_scale=1.4) # for label size\nsn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":490},"id":"YZ588U8OTEsh","executionInfo":{"status":"ok","timestamp":1607866971747,"user_tz":-330,"elapsed":1292,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"66a3b8b8-694b-40da-9c8f-73469499dad2","trusted":true},"outputs":[],"execution_count":null}]}